#!/usr/bin/env -S uv run --script
# /// script
# requires-python = ">=3.11"
# dependencies = [
#     "requests",
# ]
# ///

import json
import subprocess
import sys
from pathlib import Path

CONFIG_PATH = Path.home() / ".config" / "fast-commit" / ".env"

SYSTEM_PROMPT = """You are a git commit message generator. Given a git diff, analyse the changes and group them into logical atomic commits.

Rules:
- Each commit should represent one logical change
- Use conventional commit format: <type>(<scope>): <subject>
- Types: feat, fix, refactor, chore, docs, style, test, perf
- Subject: imperative mood, max 50 chars, no period
- Group files that belong to the same logical change together
- If all changes are one logical unit, return a single commit

Respond with ONLY a JSON array (no markdown, no explanation):
[
  {
    "files": ["path/to/file1", "path/to/file2"],
    "message": "feat(auth): add login endpoint"
  }
]

If a file is deleted, still include it in the files list - git add handles deletions.
If a file is renamed, include both old and new paths.
"""


def load_config():
    if not CONFIG_PATH.exists():
        print(f"error: config not found at {CONFIG_PATH}", file=sys.stderr)
        print(f"create it with OPENROUTER_API_KEY and MODEL", file=sys.stderr)
        sys.exit(1)
    config = {}
    for line in CONFIG_PATH.read_text().splitlines():
        line = line.strip()
        if not line or line.startswith("#"):
            continue
        key, _, value = line.partition("=")
        config[key.strip()] = value.strip().strip("\"'")
    if "OPENROUTER_API_KEY" not in config:
        print("error: OPENROUTER_API_KEY not set in config", file=sys.stderr)
        sys.exit(1)
    if "MODEL" not in config:
        print("error: MODEL not set in config", file=sys.stderr)
        sys.exit(1)
    return config


def run(cmd, check=False):
    result = subprocess.run(cmd, capture_output=True, text=True)
    if check and result.returncode != 0:
        print(f"error: command failed: {' '.join(cmd)}", file=sys.stderr)
        if result.stderr:
            print(f"  {result.stderr.strip()}", file=sys.stderr)
        sys.exit(1)
    return result.stdout, result.stderr, result.returncode


def strip_diff_noise(diff):
    """Remove noise lines from diff to save tokens."""
    lines = []
    for line in diff.splitlines():
        if line.startswith("index "):
            continue
        if line.startswith("similarity index "):
            continue
        if line.startswith("dissimilarity index "):
            continue
        lines.append(line)
    return "\n".join(lines)


def get_diff():
    staged, _, _ = run(["git", "diff", "--cached", "--name-only"])
    if staged.strip():
        diff, _, _ = run(["git", "diff", "--cached", "--minimal"])
        return strip_diff_noise(diff), "staged"
    diff, _, _ = run(["git", "diff", "--minimal"])
    if not diff.strip():
        untracked, _, _ = run(["git", "ls-files", "--others", "--exclude-standard"])
        if not untracked.strip():
            return "", "none"
        run(["git", "add", "-A"], check=True)
        diff, _, _ = run(["git", "diff", "--cached", "--minimal"])
        return strip_diff_noise(diff), "all"
    run(["git", "add", "-A"], check=True)
    diff, _, _ = run(["git", "diff", "--cached", "--minimal"])
    return strip_diff_noise(diff), "all"


MAX_DIFF_CHARS = 20000
MAX_LINES_PER_HUNK = 15
MAX_HUNKS_PER_FILE = 5


def parse_files_from_diff(diff):
    """Extract the set of files mentioned in a diff."""
    files = set()
    for line in diff.splitlines():
        if line.startswith("diff --git a/"):
            parts = line.split(" b/")
            if len(parts) == 2:
                files.add(parts[1])
        elif line.startswith("rename from "):
            files.add(line[12:])
        elif line.startswith("rename to "):
            files.add(line[10:])
    return files


def validate_commits(commits, diff_files):
    """Validate LLM output against actual diff files."""
    llm_files = set()
    for commit in commits:
        if "files" not in commit or "message" not in commit:
            print("error: LLM returned commit without 'files' or 'message' field", file=sys.stderr)
            print(f"  commit: {commit}", file=sys.stderr)
            sys.exit(1)
        for f in commit["files"]:
            llm_files.add(f)

    unknown_files = llm_files - diff_files
    if unknown_files:
        print(f"error: LLM returned files not in diff: {unknown_files}", file=sys.stderr)
        sys.exit(1)

    missing_files = diff_files - llm_files
    if missing_files:
        print(f"warning: files in diff not covered by LLM: {missing_files}", file=sys.stderr)


def compress_diff(diff):
    """Compress diff while preserving semantic information.

    Strategy:
    - Include --stat and --dirstat for overview
    - Keep all hunk headers (@@...@@) which show function context
    - Limit lines per hunk, prioritizing additions (+) over context
    - Limit total hunks per file
    """
    stat, _, _ = run(["git", "diff", "--cached", "--stat"])
    dirstat, _, _ = run(["git", "diff", "--cached", "--dirstat"])

    parts = [f"DIFF STAT:\n{stat}"]
    if dirstat.strip():
        parts.append(f"DIRECTORY CHANGES:\n{dirstat}")
    parts.append("COMPRESSED PATCHES:")

    current_file_header = None
    current_file_lines = []
    hunk_count = 0
    hunk_lines = 0
    hunk_truncated = False

    def flush_file():
        nonlocal current_file_header, current_file_lines, hunk_count
        if current_file_header:
            parts.append(current_file_header)
            parts.extend(current_file_lines)
            if hunk_count > MAX_HUNKS_PER_FILE:
                parts.append(f"[... {hunk_count - MAX_HUNKS_PER_FILE} more hunks truncated]")
        current_file_header = None
        current_file_lines = []
        hunk_count = 0

    for line in diff.splitlines():
        if line.startswith("diff --git"):
            flush_file()
            current_file_header = line
            hunk_count = 0
        elif line.startswith("@@") and " @@" in line:
            hunk_count += 1
            hunk_lines = 0
            hunk_truncated = False
            if hunk_count <= MAX_HUNKS_PER_FILE:
                current_file_lines.append(line)
        elif current_file_header and hunk_count <= MAX_HUNKS_PER_FILE:
            if line.startswith("---") or line.startswith("+++"):
                current_file_lines.append(line)
            elif line.startswith("rename ") or line.startswith("new file") or line.startswith("deleted file"):
                current_file_lines.append(line)
            elif hunk_lines < MAX_LINES_PER_HUNK:
                if line.startswith("+") or line.startswith("-"):
                    current_file_lines.append(line)
                    hunk_lines += 1
                elif line.startswith(" ") and hunk_lines < MAX_LINES_PER_HUNK // 2:
                    current_file_lines.append(line)
                    hunk_lines += 1
            elif not hunk_truncated:
                current_file_lines.append("[... hunk truncated]")
                hunk_truncated = True

    flush_file()
    return "\n".join(parts)


def call_llm(config, diff):
    import requests

    content = diff if len(diff) <= MAX_DIFF_CHARS else compress_diff(diff)

    resp = requests.post(
        "https://openrouter.ai/api/v1/chat/completions",
        headers={
            "Authorization": f"Bearer {config['OPENROUTER_API_KEY']}",
            "Content-Type": "application/json",
        },
        json={
            "model": config["MODEL"],
            "messages": [
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": content},
            ],
            "temperature": 0,
        },
        timeout=60,
    )
    if resp.status_code != 200:
        print(f"error: LLM API returned {resp.status_code}: {resp.text}", file=sys.stderr)
        sys.exit(1)
    try:
        resp_json = resp.json()
    except json.JSONDecodeError as e:
        print(f"error: failed to parse API response as JSON: {e}", file=sys.stderr)
        print(f"  response: {resp.text[:500]}", file=sys.stderr)
        sys.exit(1)
    try:
        content = resp_json["choices"][0]["message"]["content"]
    except (KeyError, IndexError) as e:
        print(f"error: unexpected API response structure: {e}", file=sys.stderr)
        print(f"  response: {resp_json}", file=sys.stderr)
        sys.exit(1)
    content = content.strip()
    if content.startswith("```"):
        content = "\n".join(content.split("\n")[1:])
    if content.endswith("```"):
        content = "\n".join(content.split("\n")[:-1])
    try:
        return json.loads(content)
    except json.JSONDecodeError as e:
        print(f"error: LLM returned invalid JSON: {e}", file=sys.stderr)
        print(f"  content: {content[:500]}", file=sys.stderr)
        sys.exit(1)


def main():
    config = load_config()

    diff, source = get_diff()
    if not diff:
        print("nothing to commit")
        return

    print(f"analysing {source} changes...")
    commits = call_llm(config, diff)

    diff_files = parse_files_from_diff(diff)
    validate_commits(commits, diff_files)

    if source == "all":
        run(["git", "reset", "HEAD"], check=True)

    for commit in commits:
        files = commit["files"]
        message = commit["message"]
        run(["git", "add", "--"] + files, check=True)
        _, stderr, code = run(["git", "commit", "-m", message])
        if code != 0:
            print(f"error: commit failed: {stderr}", file=sys.stderr)
            sys.exit(1)
        print(f"  {message}")

    _, stderr, code = run(["git", "push"])
    if code != 0:
        print(f"error: push failed: {stderr}", file=sys.stderr)
        sys.exit(1)
    print("pushed")


if __name__ == "__main__":
    main()
